---
sidebar_label: Requesty
---

# Utiliser Requesty avec Kilo Code

Kilo Code supporte l'accès aux modèles via la plateforme d'IA [Requesty](https://www.requesty.ai/). Requesty fournit une API facile et optimisée pour interagir avec plus de 150 modèles de langage volumineux (LLMs).

**Site Web :** [https://www.requesty.ai/](https://www.requesty.ai/)

## Obtenir une Clé API

1.  **S'inscrire/Se connecter :** Allez au [site web Requesty](https://www.requesty.ai/) et créez un compte ou connectez-vous.
2.  **Obtenir une Clé API :** Vous pouvez obtenir une clé API depuis la section [Gestion API](https://app.requesty.ai/manage-api) de votre tableau de bord Requesty.

## Modèles Supportés

Requesty fournit l'accès à une large gamme de modèles. Kilo Code récupérera automatiquement la dernière liste des modèles disponibles. Vous pouvez voir la liste complète des modèles disponibles sur la page [Liste des Modèles](https://app.requesty.ai/router/list).

## Configuration dans Kilo Code

1.  **Ouvrir les Paramètres Kilo Code :** Cliquez sur l'icône d'engrenage (<Codicon name="gear" />) dans le panneau Kilo Code.
2.  **Sélectionner le Fournisseur :** Choisissez "Requesty" dans le menu déroulant "Fournisseur API".
3.  **Saisir la Clé API :** Collez votre clé API Requesty dans le champ "Clé API Requesty".
4.  **Sélectionner le Modèle :** Choisissez votre modèle désiré dans le menu déroulant "Modèle".

## Conseils et Notes

- **Optimisations :** Requesty offre une gamme d'optimisations de coût en vol pour réduire vos coûts.
- **Facturation unifiée et simplifiée :** Accès illimité à tous les fournisseurs et modèles, recharges de solde automatiques et plus via une seule [clé API](https://app.requesty.ai/manage-api).
- **Suivi de coût :** Suivez le coût par modèle, langage de codage, fichier modifié, et plus via le [tableau de bord Coût](https://app.requesty.ai/cost-management) ou l'[extension VS.code Requesty](https://marketplace.visualstudio.com/items?itemName=Requesty.requesty).
- **Stats et logs :** Voyez votre [tableau de bord de stats de codage](https://app.requesty.ai/usage-stats) ou parcourez vos [logs d'interaction LLM](https://app.requesty.ai/logs).
- **Politiques de fallback :** Gardez votre LLM fonctionnant pour vous avec des politiques de fallback quand les fournisseurs sont en panne.

* **Cache de Prompts :** Certains fournisseurs supportent le cache de prompts. [Rechercher des modèles avec cache](https://app.requesty.ai/router/list).

## Ressources pertinentes

- [Chaîne YouTube Requesty](https://www.youtube.com/@requestyAI) :
- [Discord Requesty](https://requesty.ai/discord)
